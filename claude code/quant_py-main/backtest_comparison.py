"""
ë°±í…ŒìŠ¤íŠ¸ ë¹„êµ: Top 5 vs Top 10, ë™ì¼ë¹„ì¤‘ vs ìˆœìœ„ê°€ì¤‘
- í•œ ë²ˆì˜ ì „ëµ ì‹¤í–‰ìœ¼ë¡œ 4ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ë™ì‹œ ë¹„êµ
- ë¶„ê¸°ë³„ ë¦¬ë°¸ëŸ°ì‹± (2015-2025)
"""

import pandas as pd
import numpy as np
import warnings
from datetime import datetime, timedelta
from pathlib import Path
import json
import sys

warnings.filterwarnings('ignore')

from fnguide_crawler import get_all_financial_statements, extract_magic_formula_data
from data_collector import DataCollector
from strategy_b_multifactor import MultiFactorStrategy

# ì„¤ì •
START_DATE = '20150101'
END_DATE = '20251231'
IS_END_DATE = '20231231'
MIN_MARKET_CAP = 1000   # ì–µì›
MIN_TRADING_VALUE = 50   # ì–µì›
N_STOCKS = 10            # ì „ëµì—ì„œ 10ê°œ ì„ ì • (Top 5ëŠ” ì—¬ê¸°ì„œ ì˜ë¼ëƒ„)

# ê±°ë˜ë¹„ìš©
COMMISSION = 0.00015
TAX = 0.0023
BASE_SLIPPAGE = 0.001

OUTPUT_DIR = Path(__file__).parent / 'backtest_results'
OUTPUT_DIR.mkdir(exist_ok=True)

# 4ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤
SCENARIOS = {
    'top5_equal':   {'n': 5,  'weighted': False, 'label': 'Top 5 ë™ì¼ë¹„ì¤‘'},
    'top5_ranked':  {'n': 5,  'weighted': True,  'label': 'Top 5 ìˆœìœ„ê°€ì¤‘'},
    'top10_equal':  {'n': 10, 'weighted': False, 'label': 'Top 10 ë™ì¼ë¹„ì¤‘'},
    'top10_ranked': {'n': 10, 'weighted': True,  'label': 'Top 10 ìˆœìœ„ê°€ì¤‘'},
}


def rank_weights(n):
    """
    ìˆœìœ„ ê°€ì¤‘ì¹˜: 1ìœ„ = n, 2ìœ„ = n-1, ... nìœ„ = 1
    ì •ê·œí™”í•˜ì—¬ í•©ì´ 1ì´ ë˜ë„ë¡
    """
    raw = np.array([n - i for i in range(n)], dtype=float)
    return raw / raw.sum()


def generate_rebalance_dates(start_year=2015, end_year=2025):
    """ë¶„ê¸°ë³„ ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ (3, 6, 9, 12ì›” ë§)"""
    dates = []
    for year in range(start_year, end_year + 1):
        for month in [3, 6, 9, 12]:
            if month == 12:
                date = f"{year}1231"
            else:
                next_month = month + 1
                last_day = (datetime(year, next_month, 1) - timedelta(days=1)).day
                date = f"{year}{month:02d}{last_day:02d}"
            dates.append(date)
    return dates


def get_universe_for_date(collector, date):
    """íŠ¹ì • ë‚ ì§œì˜ ìœ ë‹ˆë²„ìŠ¤"""
    try:
        market_cap_df = collector.get_market_cap(date, market='ALL')
        if market_cap_df.empty:
            return pd.DataFrame(), []

        market_cap_df['ì‹œê°€ì´ì•¡_ì–µ'] = market_cap_df['ì‹œê°€ì´ì•¡'] / 1e8
        filtered = market_cap_df[market_cap_df['ì‹œê°€ì´ì•¡_ì–µ'] >= MIN_MARKET_CAP].copy()

        filtered['ê±°ë˜ëŒ€ê¸ˆ_ì–µ'] = filtered['ê±°ë˜ëŒ€ê¸ˆ'] / 1e8
        filtered = filtered[filtered['ê±°ë˜ëŒ€ê¸ˆ_ì–µ'] >= MIN_TRADING_VALUE]

        from pykrx import stock
        exclude_kw = ['ê¸ˆìœµ', 'ì€í–‰', 'ì¦ê¶Œ', 'ë³´í—˜', 'ìºí”¼íƒˆ', 'ì¹´ë“œ', 'ì €ì¶•',
                      'ì§€ì£¼', 'í™€ë”©ìŠ¤', 'SPAC', 'ìŠ¤íŒ©', 'ë¦¬ì¸ ', 'REIT']
        valid = []
        for ticker in filtered.index:
            try:
                name = stock.get_market_ticker_name(ticker)
                if not any(kw in name for kw in exclude_kw):
                    valid.append(ticker)
            except Exception:
                continue

        return filtered.loc[filtered.index.isin(valid)], valid
    except Exception as e:
        print(f"  ìœ ë‹ˆë²„ìŠ¤ ì‹¤íŒ¨ ({date}): {e}")
        return pd.DataFrame(), []


def run_strategy(collector, date, tickers, universe_df):
    """ì „ëµ B ì‹¤í–‰ â†’ ìƒìœ„ 10ê°œ ë°˜í™˜ (ìˆœìœ„ìˆœ)"""
    if not tickers:
        return pd.DataFrame()

    try:
        fs_data = get_all_financial_statements(tickers, use_cache=True)
        magic_df = extract_magic_formula_data(fs_data, base_date=date)
        if magic_df.empty:
            return pd.DataFrame()

        from pykrx import stock as pykrx_stock
        try:
            mc_kospi = pykrx_stock.get_market_cap(date, market='KOSPI')
            mc_kosdaq = pykrx_stock.get_market_cap(date, market='KOSDAQ')
            if not mc_kospi.empty:
                mc_kospi['ì„¹í„°'] = 'KOSPI'
            if not mc_kosdaq.empty:
                mc_kosdaq['ì„¹í„°'] = 'KOSDAQ'
            mc_all = pd.concat([mc_kospi, mc_kosdaq])
            magic_df = magic_df.merge(
                mc_all[['ì‹œê°€ì´ì•¡', 'ì„¹í„°']],
                left_on='ì¢…ëª©ì½”ë“œ', right_index=True, how='left'
            )
        except Exception:
            magic_df = magic_df.merge(
                universe_df[['ì‹œê°€ì´ì•¡']],
                left_on='ì¢…ëª©ì½”ë“œ', right_index=True, how='left'
            )

        magic_df['ì‹œê°€ì´ì•¡'] = magic_df['ì‹œê°€ì´ì•¡'] / 1e8

        # ëª¨ë©˜í…€ ê°€ê²© ë°ì´í„°
        end_dt = datetime.strptime(date, '%Y%m%d')
        start_dt = end_dt - timedelta(days=400)
        try:
            price_df = collector.get_all_ohlcv(
                magic_df['ì¢…ëª©ì½”ë“œ'].tolist(),
                start_dt.strftime('%Y%m%d'), date
            )
        except Exception:
            price_df = None

        strategy = MultiFactorStrategy()
        selected, _ = strategy.run(magic_df, price_df=price_df, n_stocks=N_STOCKS)
        return selected

    except Exception as e:
        print(f"  ì „ëµ ì‹¤íŒ¨ ({date}): {e}")
        return pd.DataFrame()


def get_stock_returns(collector, tickers, start_date, end_date):
    """ê° ì¢…ëª©ì˜ ì¼ë³„ ìˆ˜ìµë¥  ìˆ˜ì§‘ â†’ DataFrame"""
    returns_dict = {}
    for ticker in tickers:
        try:
            ohlcv = collector.get_ohlcv(ticker, start_date, end_date)
            if ohlcv.empty:
                # ìƒì¥íì§€
                returns_dict[ticker] = pd.Series(
                    -1.0, index=[pd.to_datetime(start_date)]
                )
            else:
                returns_dict[ticker] = ohlcv['ì¢…ê°€'].pct_change()
        except Exception:
            returns_dict[ticker] = pd.Series(
                -1.0, index=[pd.to_datetime(start_date)]
            )
    if not returns_dict:
        return pd.DataFrame()
    return pd.concat(returns_dict, axis=1)


def weighted_portfolio_return(returns_df, weights):
    """ê°€ì¤‘ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ """
    # returns_df ì»¬ëŸ¼ ìˆ˜ì™€ weights ê¸¸ì´ ë§ì¶”ê¸°
    n = min(len(weights), returns_df.shape[1])
    w = weights[:n]
    w = w / w.sum()  # ì¬ì •ê·œí™” (ì¢…ëª© ìˆ˜ ë¶€ì¡± ì‹œ)
    return (returns_df.iloc[:, :n] * w).sum(axis=1)


def apply_transaction_cost(portfolio_return, universe_df):
    """ê±°ë˜ë¹„ìš© ì°¨ê°"""
    if portfolio_return.empty or universe_df is None:
        return portfolio_return

    avg_tv = universe_df.get('ê±°ë˜ëŒ€ê¸ˆ', pd.Series()).mean()
    if pd.isna(avg_tv):
        avg_tv = 1e9

    impact = min(100_000_000 / N_STOCKS / max(avg_tv, 1) * 10, 0.009)
    buy_cost = COMMISSION + BASE_SLIPPAGE + impact
    sell_cost = COMMISSION + TAX + BASE_SLIPPAGE + impact

    ret = portfolio_return.copy()
    if len(ret) > 0:
        ret.iloc[0] -= buy_cost
    if len(ret) > 1:
        ret.iloc[-1] -= sell_cost
    return ret


def calc_metrics(returns, label=''):
    """ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
    if returns.empty or len(returns) < 20:
        return {}

    cum = (1 + returns).cumprod()
    total = cum.iloc[-1] - 1
    years = len(returns) / 252

    cagr = cum.iloc[-1] ** (1 / years) - 1 if years > 0 and cum.iloc[-1] > 0 else 0
    vol = returns.std() * np.sqrt(252)
    peak = cum.cummax()
    dd = (cum - peak) / peak
    mdd = dd.min()
    sharpe = (cagr - 0.03) / vol if vol > 0 else 0

    down = returns[returns < 0]
    down_std = down.std() * np.sqrt(252) if len(down) > 0 else 0
    sortino = (cagr - 0.03) / down_std if down_std > 0 else 0
    calmar = abs(cagr / mdd) if mdd != 0 else 0
    win_rate = (returns > 0).sum() / len(returns) * 100

    return {
        'label': label,
        'total_return': total * 100,
        'cagr': cagr * 100,
        'volatility': vol * 100,
        'mdd': mdd * 100,
        'sharpe': sharpe,
        'sortino': sortino,
        'calmar': calmar,
        'win_rate': win_rate,
        'trading_days': len(returns),
    }


def run_comparison_backtest():
    """ë©”ì¸ ë¹„êµ ë°±í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ë°±í…ŒìŠ¤íŠ¸ ë¹„êµ: Top 5 vs Top 10, ë™ì¼ë¹„ì¤‘ vs ìˆœìœ„ê°€ì¤‘")
    print(f"ê¸°ê°„: {START_DATE} ~ {END_DATE}")
    print(f"ë¦¬ë°¸ëŸ°ì‹±: ë¶„ê¸°ë³„ (3/6/9/12ì›”)")
    print("=" * 80)

    collector = DataCollector(start_date=START_DATE, end_date=END_DATE)
    rebal_dates = generate_rebalance_dates(2015, 2025)

    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìˆ˜ìµë¥  ëˆ„ì 
    scenario_returns = {k: [] for k in SCENARIOS}

    # ë²¤ì¹˜ë§ˆí¬ (KOSPI200)
    from pykrx import stock as pykrx_stock
    try:
        idx = pykrx_stock.get_index_ohlcv(START_DATE, END_DATE, '1028')
        close_col = [c for c in idx.columns if 'ì¢…ê°€' in c]
        close_col = close_col[0] if close_col else idx.columns[3]
        bench_returns = idx[close_col].pct_change().dropna()
        print(f"ë²¤ì¹˜ë§ˆí¬ (KOSPI200) ë¡œë“œ ì™„ë£Œ: {len(bench_returns)}ì¼")
    except Exception as e:
        print(f"ë²¤ì¹˜ë§ˆí¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        bench_returns = pd.Series(dtype=float)

    total_quarters = len(rebal_dates) - 1
    for i in range(total_quarters):
        rebal = rebal_dates[i]
        next_rebal = rebal_dates[i + 1]
        print(f"\n[{i+1}/{total_quarters}] {rebal} â†’ {next_rebal}")

        # 1. ìœ ë‹ˆë²„ìŠ¤
        universe_df, tickers = get_universe_for_date(collector, rebal)
        if not tickers:
            print("  ìœ ë‹ˆë²„ìŠ¤ ì—†ìŒ")
            continue
        print(f"  ìœ ë‹ˆë²„ìŠ¤: {len(tickers)}ê°œ")

        # 2. ì „ëµ ì‹¤í–‰ (Top 10)
        selected = run_strategy(collector, rebal, tickers, universe_df)
        if selected.empty:
            print("  ì„ ì • ì‹¤íŒ¨")
            continue

        top10_tickers = selected['ì¢…ëª©ì½”ë“œ'].tolist()[:10]
        top5_tickers = top10_tickers[:5]
        print(f"  ì„ ì •: {len(top10_tickers)}ê°œ (Top 5: {len(top5_tickers)}ê°œ)")

        # 3. ìˆ˜ìµë¥  ìˆ˜ì§‘ (10ê°œ ì¢…ëª© í•œë²ˆì—)
        returns_df = get_stock_returns(collector, top10_tickers, rebal, next_rebal)
        if returns_df.empty:
            print("  ìˆ˜ìµë¥  ì—†ìŒ")
            continue

        # 4. ì‹œë‚˜ë¦¬ì˜¤ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
        for key, cfg in SCENARIOS.items():
            n = cfg['n']
            sub_returns = returns_df.iloc[:, :n]  # Top N ì¢…ëª©ë§Œ

            if sub_returns.empty:
                continue

            if cfg['weighted']:
                w = rank_weights(min(n, sub_returns.shape[1]))
                port_ret = weighted_portfolio_return(sub_returns, w)
            else:
                port_ret = sub_returns.mean(axis=1)

            port_ret = apply_transaction_cost(port_ret, universe_df)
            scenario_returns[key].append(port_ret)

        # ì§„í–‰ë¥  í‘œì‹œ
        top_names = []
        for t in top5_tickers[:3]:
            try:
                name = pykrx_stock.get_market_ticker_name(t)
                top_names.append(name)
            except Exception:
                top_names.append(t)
        print(f"  Top 3: {', '.join(top_names)}")

    # === ê²°ê³¼ ì§‘ê³„ ===
    print("\n" + "=" * 80)
    print("                    ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ")
    print("=" * 80)

    all_metrics = {}
    all_cumulative = {}

    for key, cfg in SCENARIOS.items():
        rets = scenario_returns[key]
        if not rets:
            print(f"\n{cfg['label']}: ë°ì´í„° ì—†ìŒ")
            continue

        full_ret = pd.concat(rets)
        full_ret = full_ret[~full_ret.index.duplicated(keep='first')].sort_index()

        # ì „ì²´ ê¸°ê°„
        metrics = calc_metrics(full_ret, cfg['label'])
        all_metrics[key] = metrics

        # ëˆ„ì  ìˆ˜ìµë¥ 
        cum = (1 + full_ret).cumprod()
        all_cumulative[key] = cum

        # IS / OOS
        is_ret = full_ret[full_ret.index <= IS_END_DATE]
        oos_ret = full_ret[full_ret.index > IS_END_DATE]
        is_m = calc_metrics(is_ret, f"{cfg['label']} [IS]")
        oos_m = calc_metrics(oos_ret, f"{cfg['label']} [OOS]")

        print(f"\n{'â”€' * 50}")
        print(f"ğŸ“Š {cfg['label']}")
        print(f"{'â”€' * 50}")
        print(f"  ì „ì²´  | CAGR {metrics.get('cagr',0):+.1f}%  MDD {metrics.get('mdd',0):.1f}%  Sharpe {metrics.get('sharpe',0):.2f}  Sortino {metrics.get('sortino',0):.2f}")
        print(f"  IS    | CAGR {is_m.get('cagr',0):+.1f}%  MDD {is_m.get('mdd',0):.1f}%  Sharpe {is_m.get('sharpe',0):.2f}")
        print(f"  OOS   | CAGR {oos_m.get('cagr',0):+.1f}%  MDD {oos_m.get('mdd',0):.1f}%  Sharpe {oos_m.get('sharpe',0):.2f}")

        # ì €ì¥
        full_ret.to_csv(OUTPUT_DIR / f'comparison_{key}_returns.csv')
        cum.to_csv(OUTPUT_DIR / f'comparison_{key}_cumulative.csv')

    # ë²¤ì¹˜ë§ˆí¬ ì§€í‘œ
    if not bench_returns.empty:
        bench_m = calc_metrics(bench_returns, 'KOSPI200')
        all_metrics['kospi200'] = bench_m
        print(f"\n{'â”€' * 50}")
        print(f"ğŸ“Š KOSPI200 (ë²¤ì¹˜ë§ˆí¬)")
        print(f"{'â”€' * 50}")
        print(f"  ì „ì²´  | CAGR {bench_m.get('cagr',0):+.1f}%  MDD {bench_m.get('mdd',0):.1f}%  Sharpe {bench_m.get('sharpe',0):.2f}")

    # === ë¹„êµ í…Œì´ë¸” ===
    print("\n" + "=" * 80)
    print("                    ë¹„êµ ìš”ì•½")
    print("=" * 80)

    headers = ['ì‹œë‚˜ë¦¬ì˜¤', 'CAGR', 'MDD', 'Sharpe', 'Sortino', 'Calmar', 'Win%']
    print(f"{'ì‹œë‚˜ë¦¬ì˜¤':<22} {'CAGR':>8} {'MDD':>8} {'Sharpe':>8} {'Sortino':>8} {'Calmar':>8} {'Win%':>6}")
    print("â”€" * 80)
    for key, m in all_metrics.items():
        label = m.get('label', key)
        print(f"{label:<22} {m.get('cagr',0):>+7.1f}% {m.get('mdd',0):>7.1f}% {m.get('sharpe',0):>8.2f} {m.get('sortino',0):>8.2f} {m.get('calmar',0):>8.2f} {m.get('win_rate',0):>5.1f}%")

    # === Top 5 vs Top 10 ì°¨ì´ ===
    if 'top5_equal' in all_metrics and 'top10_equal' in all_metrics:
        d_cagr = all_metrics['top5_equal']['cagr'] - all_metrics['top10_equal']['cagr']
        d_mdd = all_metrics['top5_equal']['mdd'] - all_metrics['top10_equal']['mdd']
        print(f"\nTop 5 vs Top 10 (ë™ì¼ë¹„ì¤‘): CAGR ì°¨ì´ {d_cagr:+.1f}%p, MDD ì°¨ì´ {d_mdd:+.1f}%p")

    if 'top5_ranked' in all_metrics and 'top10_ranked' in all_metrics:
        d_cagr = all_metrics['top5_ranked']['cagr'] - all_metrics['top10_ranked']['cagr']
        d_mdd = all_metrics['top5_ranked']['mdd'] - all_metrics['top10_ranked']['mdd']
        print(f"Top 5 vs Top 10 (ìˆœìœ„ê°€ì¤‘): CAGR ì°¨ì´ {d_cagr:+.1f}%p, MDD ì°¨ì´ {d_mdd:+.1f}%p")

    # === ë™ì¼ë¹„ì¤‘ vs ìˆœìœ„ê°€ì¤‘ ===
    if 'top5_equal' in all_metrics and 'top5_ranked' in all_metrics:
        d_cagr = all_metrics['top5_ranked']['cagr'] - all_metrics['top5_equal']['cagr']
        print(f"\në™ì¼ë¹„ì¤‘ vs ìˆœìœ„ê°€ì¤‘ (Top 5): CAGR ì°¨ì´ {d_cagr:+.1f}%p")

    if 'top10_equal' in all_metrics and 'top10_ranked' in all_metrics:
        d_cagr = all_metrics['top10_ranked']['cagr'] - all_metrics['top10_equal']['cagr']
        print(f"ë™ì¼ë¹„ì¤‘ vs ìˆœìœ„ê°€ì¤‘ (Top 10): CAGR ì°¨ì´ {d_cagr:+.1f}%p")

    # JSON ì €ì¥
    with open(OUTPUT_DIR / 'comparison_metrics.json', 'w', encoding='utf-8') as f:
        json.dump(all_metrics, f, indent=2, ensure_ascii=False, default=str)

    print(f"\nê²°ê³¼ ì €ì¥: {OUTPUT_DIR}")
    print("=" * 80)

    return all_metrics


if __name__ == '__main__':
    run_comparison_backtest()
